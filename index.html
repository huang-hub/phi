<!DOCTYPE html>
<html lang="zh">
<head>
	<script defer data-domain="phi-2.top" src="https://plausible.io/js/script.js"></script>

  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Phi-2: The surprising power of small language models</title>
  <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet">
</head>
<body>
  <header class="absolute inset-x-0 top-0 z-30 mb-10 lg:mb-0"><nav class="mx-auto flex max-w-7xl items-center justify-between p-6 lg:px-8" aria-label="Global"><div class="flex lg:flex-1"><a href="/" class="-m-1.5 p-1.5 flex items-center justify-center space-x-2"><img src="https://upload.wikimedia.org/wikipedia/commons/2/28/Phi.svg" alt="" class="w-14 h-14"><p class="font-bold md:text-xl lg:text-xl text-black flex items-center">Phi-2</p></a></div><div class="flex lg:hidden"><button type="button" class="-m-2.5 inline-flex items-center justify-center rounded-md p-2.5 text-gray-700"><span class="sr-only">Open main menu</span><svg xmlns="https://upload.wikimedia.org/wikipedia/commons/2/28/Phi.svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" class="h-6 w-6"><path stroke-linecap="round" stroke-linejoin="round" d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5"></path></svg></button></div><div class="hidden lg:flex lg:gap-x-12 z-index"><a href="/" class="text-sm font-semibold leading-6 text-gray-900">Home</a><a href="https://www.phi-2.top/Phi-2.html" class="text-sm font-semibold leading-6 text-gray-900">Phi-2</a><a href="/Phi-1-1.5" class="text-sm font-semibold leading-6 text-gray-900">Phi-1-1.5</a><a href="/blogs" class="text-sm font-semibold leading-6 text-gray-900">Blogs</a></div><div class="hidden lg:flex lg:flex-1 lg:justify-end"><button class="-mx-3 block rounded-lg px-3 py-2.5 text-base font-semibold leading-7 text-gray-900 hover:bg-gray-50">Log in</button></div></nav><div style="position:fixed;top:1px;left:1px;width:1px;height:0;padding:0;margin:-1px;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border-width:0;display:none"></div></header>
<nav class="mx-auto flex max-w-7xl items-center justify-between p-6 lg:px-8" aria-label="Global"><div class="flex lg:flex-1"><a href="/" class="-m-1.5 p-1.5 flex items-center justify-center space-x-2"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/28/Phi.svg/135px-Phi.svg.png?20060813031530" alt="Phi-2  Logo" class="w-14 h-14"><p class="font-bold md:text-xl lg:text-xl text-black flex items-center">Phi-2</p></a></div><div class="flex lg:hidden"><button type="button" class="-m-2.5 inline-flex items-center justify-center rounded-md p-2.5 text-gray-700"><span class="sr-only">Open main menu</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" class="h-6 w-6"><path stroke-linecap="round" stroke-linejoin="round" d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5"></path></svg></button></div><div class="hidden lg:flex lg:gap-x-12 z-index"><a href="/" class="text-sm font-semibold leading-6 text-gray-900">Home</a><a href="/www.phi-2.top/phi-2.html" class="text-sm font-semibold leading-6 text-gray-900">Phi-2</a><a href="/Phi-1-1.5" class="text-sm font-semibold leading-6 text-gray-900">Phi-1-1.5</a><a href="/blogs" class="text-sm font-semibold leading-6 text-gray-900">Blogs</a></div><div class="hidden lg:flex lg:flex-1 lg:justify-end"><button class="-mx-3 block rounded-lg px-3 py-2.5 text-base font-semibold leading-7 text-gray-900 hover:bg-gray-50">Log in</button></div></nav>
<section>

    <header>
        <!-- Hero Container -->
        <div class="mx-auto w-full max-w-7xl px-5 py-16 md:px-10 md:py-24 lg:py-32">
          <!-- Component -->
          <div class="grid items-center justify-items-start gap-8 sm:gap-20 lg:grid-cols-2">
            <!-- Hero Content -->
            <div class="flex flex-col">
              <!-- Hero Title -->
              <h1 class="mb-4 text-4xl font-bold md:text-6xl">Phi-2: The surprising power of small language models.</h1>
              <p class="mb-6 max-w-lg text-sm text-[#636262] sm:text-xl md:mb-10 lg:mb-12"> Phi-2(opens in new tab), a 2.7 billion-parameter language model that demonstrates outstanding reasoning and language understanding capabilities.</p>
              <!-- Hero Button -->
              <a href="https://www.phi-2.top/phi-2.html" class="mb-6 mr-6 w-36 rounded-md bg-black px-6 py-3 text-center font-semibold text-white md:mb-10 lg:mb-12 lg:mr-8">Phi-2</a>
              <!-- Hero Comment -->
              <div class="max-w-xs">
                <p class="mb-4 text-sm text-[#636262]">develop a suite of small language models (SLMs) known as "Phi-1/-1.5/2"</p>
                <div class="flex items-start gap-11 sm:flex-row">
                  <div class="flex">
                    <img src="https://girff.com/wp-content/uploads/2023/12/Phi-2-300x153.jpg" alt="" class="mr-2 inline-block h-7 w-7 sm:h-7" />
                    <p class="text-sm font-bold">Girff</p>
                  </div>
                  <div class="flex">
                    <p class="mr-2 text-sm font-bold">5.0</p>
                    <img src="https://assets.website-files.com/6357722e2a5f19121d37f84d/6357722e2a5f195bcf37f880_Vector.svg" alt="" class="mr-1.5 inline-block w-4" />
                    <img src="https://assets.website-files.com/6357722e2a5f19121d37f84d/6357722e2a5f195bcf37f880_Vector.svg" alt="" class="mr-1.5 inline-block w-4" />
                    <img src="https://assets.website-files.com/6357722e2a5f19121d37f84d/6357722e2a5f195bcf37f880_Vector.svg" alt="" class="mr-1.5 inline-block w-4" />
                    <img src="https://assets.website-files.com/6357722e2a5f19121d37f84d/6357722e2a5f195bcf37f880_Vector.svg" alt="" class="mr-1.5 inline-block w-4" />
                    <img src="https://assets.website-files.com/6357722e2a5f19121d37f84d/6357722e2a5f195bcf37f880_Vector.svg" alt="" class="mr-1.5 inline-block w-4" />
                  </div>
                </div>
              </div>
            </div>
            <!-- Hero Image -->
            <img src="https://girff.com/wp-content/uploads/2023/12/Phi-2-1-e1702470412906.jpg" alt="" class="inline-block h-full w-full max-w-[640px]" />
          </div>
        </div>
      </header>
      
<section>
    <!-- Container -->
    <div class="mx-auto w-full max-w-7xl px-5 py-16 md:px-10 md:py-24 lg:py-32">
      <!-- Component -->
      <div class="mx-auto mb-8 flex max-w-3xl flex-col items-center text-center md:mb-12 lg:mb-16">
        <h2 class="text-3xl font-bold md:text-5xl">Phi-2: a surprisingly powerful 2.7B parameters language model</h2>
        <p class="mx-auto mb-8 mt-4 max-w-lg text-base text-[#636262] md:mb-12 md:text-lg lg:mb-16">Phi-2 is a Transformer-based model with a next word prediction objective, trained on 1.4T tokens from a mix of synthetic and web datasets for NLP and coding.</p>
        <div class="flex justify-center">
          <div class="mr-6 md:mr-10 lg:mr-12">
            <h3 class="text-2xl font-bold md:text-3xl">2.7B</h3>
            <p class="text-sm text-[#636262]">parameters</p>
          </div>
          <div>
            <h3 class="text-2xl font-bold md:text-3xl">1.4T</h3>
            <p class="text-sm text-[#636262]">tokens</p>
          </div>
        </div>
      </div>
      <img src="https://girff.com/wp-content/uploads/2023/12/Phi2-BlogHeroFeature.jpg" alt="" class="inline-block h-full w-full object-cover" />
      <div>

      
    </div>
 
<section>
    <!-- Container -->
    <div class="mx-auto w-full max-w-7xl px-5 py-16 md:px-10 md:py-24 lg:py-32">
      <!-- Component -->
      <div class="mx-auto mb-8 flex max-w-3xl flex-col items-center text-center md:mb-12 lg:mb-16">
        <h2 class="text-3xl font-bold md:text-5xl"> Azure AI Studio</h2>
        <p class="mx-auto mb-8 mt-4 max-w-lg text-base text-[#636262] md:mb-12 md:text-lg lg:mb-16">Your platform for developing generative AI solutions and custom copilots</p>
        <div class="flex justify-center">
          <div class="mr-6 md:mr-10 lg:mr-12">
            <h3 class="text-2xl font-bold md:text-3xl">Phi-1</h3>
            <p class="text-sm text-[#636262]">1.3B arameters</p>
          </div>
          <div class="mr-6 md:mr-10 lg:mr-12">
            <h3 class="text-2xl font-bold md:text-3xl">Phi-1.5</h3>
            <p class="text-sm text-[#636262]"> 1.3B parameters</p>
          </div>
          <div class="mr-6 md:mr-10 lg:mr-12">
            <h3 class="text-2xl font-bold md:text-3xl">Phi-2</h3>
            <p class="text-sm text-[#636262]"> 2.7B parameters</p>
          </div>
        </div>
      </div>
      <!-- Image -->
      <img src="https://techcommunity.microsoft.com/t5/image/serverpage/image-id/526126i79484E9AE81238B1/image-size/large?v=v2&px=999" alt="" class="inline-block h-full w-full object-cover" alt="" class="inline-block h-full w-full object-cover" />
    </div>
	<!-- Component -->
      <div class="mx-auto mb-8 flex max-w-3xl flex-col items-center text-center md:mb-12 lg:mb-16">
        <h2 class="text-3xl font-bold md:text-5xl"> Microsoft-Phi-2</h2>
<iframe
	src="https://randomblock1-phi-2.hf.space"
	frameborder="0"
	width="850"
	height="720"
></iframe>
	      <p>Phi-2 is a Transformer with <strong>2.7 billion</strong> parameters. It was trained using the same data sources as <a rel="noopener nofollow" href="https://www.phi-2.top">Phi-1.5</a>, augmented with a new data source that consists of various NLP synthetic texts and filtered websites (for safety and educational value). When assessed against benchmarks testing common sense, language understanding, and logical reasoning, Phi-2 showcased a nearly state-of-the-art performance among models with less than 13 billion parameters.</p>
 <p class="mx-auto mb-8 mt-4 max-w-lg text-base text-[#636262] md:mb-12 md:text-lg lg:mb-16">Your platform for developing generative AI solutions and custom copilots</p>
<div class="single-post__content block-content content-container" itemprop="articleBody" data-bi-an="post-body">

						
<h3 class="wp-block-heading" id="contributors">Contributors</h3>



<p><a href="https://www.microsoft.com/en-us/research/people/maabdin/">Marah Abdin</a>, <a href="https://www.microsoft.com/en-us/research/people/jyotianeja/">Jyoti Aneja</a>, <a href="https://www.microsoft.com/en-us/research/people/sebubeck/">Sebastien Bubeck</a>, Caio César Teodoro Mendes, <a href="https://www.microsoft.com/en-us/research/people/wzchen/">Weizhu Chen</a>, Allie Del Giorno, <a href="https://www.microsoft.com/en-us/research/people/roneneldan/">Ronen Eldan</a>, <a href="https://www.microsoft.com/en-us/research/people/sigopi/">Sivakanth Gopi</a>, <a href="https://www.microsoft.com/en-us/research/people/suriyag/">Suriya Gunasekar</a>, <a href="https://www.microsoft.com/en-us/research/people/mojavaheripi/">Mojan Javaheripi</a>, <a href="https://www.microsoft.com/en-us/research/people/pkauffmann/">Piero Kauffmann</a>, <a href="https://www.microsoft.com/en-us/research/people/yintatlee/">Yin Tat Lee</a>, Yuanzhi Li, <a href="https://www.microsoft.com/en-us/research/people/anhnguyen/">Anh Nguyen</a>, <a href="https://www.microsoft.com/en-us/research/people/gderosa/">Gustavo de Rosa</a>, <a href="https://www.microsoft.com/en-us/research/people/olsaarik/">Olli Saarikivi</a>, <a href="https://www.microsoft.com/en-us/research/people/adilsalim/">Adil Salim</a>, <a href="https://www.microsoft.com/en-us/research/people/shitals/">Shital Shah</a>, Michael Santacroce, Harkirat Singh Behl, <a href="https://www.microsoft.com/en-us/research/blog/tag/adam-kalai/">Adam Taumann Kalai</a>, <a href="https://www.microsoft.com/en-us/research/people/wanxin/">Xin Wang</a>, <a href="https://www.microsoft.com/en-us/research/people/rachelward/">Rachel Ward</a>, <a href="https://www.microsoft.com/en-us/research/people/pwitte/">Philipp Witte</a>, <a href="https://www.microsoft.com/en-us/research/people/cyrilzhang/">Cyril Zhang</a>, Yi Zhang</p>



<figure class="wp-block-image aligncenter size-full"><img fetchpriority="high" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1.jpg" alt="Satya Nadella on stage at Microsoft Ignite 2023 announcing Phi-2." class="wp-image-991311" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-343x193.jpg 343w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="(max-width: 1400px) 100vw, 1400px"><figcaption class="wp-element-caption"><strong>Figure 1. </strong>Satya Nadella announcing Phi-2 at Microsoft Ignite 2023.</figcaption></figure>



<p>Over the past few months, our Machine Learning Foundations team at Microsoft Research has released a suite of small language models (SLMs) called “Phi” that achieve remarkable performance on a variety of benchmarks. Our first model, the 1.3 billion parameter <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://huggingface.co/microsoft/phi-1" target="_blank" rel="noreferrer noopener"><strong>Phi-1</strong><span class="sr-only"> (opens in new tab)</span></a>, achieved state-of-the-art performance on Python coding among existing SLMs (specifically on the HumanEval and MBPP benchmarks). We then extended our focus to common sense reasoning and language understanding and created a new 1.3 billion parameter model named <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://huggingface.co/microsoft/phi-1_5" target="_blank" rel="noreferrer noopener"><strong>Phi-1.5</strong><span class="sr-only"> (opens in new tab)</span></a>, with performance comparable to models 5x larger.</p>



<p>We are now releasing <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://ml.azure.com/registries/azureml-msr/models/microsoft-phi-2/version/3?tid=72f988bf-86f1-41af-91ab-2d7cd011db47#overview" target="_blank" rel="noreferrer noopener"><strong>Phi-2</strong><span class="sr-only"> (opens in new tab)</span></a>, a 2.7 billion-parameter language model that demonstrates outstanding reasoning and language understanding capabilities, showcasing state-of-the-art performance among base language models with less than 13 billion parameters. On complex benchmarks Phi-2 matches or outperforms models up to 25x larger, thanks to new innovations in model scaling and training data curation.</p>



<p>With its compact size, Phi-2 is an ideal playground for researchers, including for exploration around mechanistic interpretability, safety improvements, or fine-tuning experimentation on a variety of tasks. We have made <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://ml.azure.com/registries/azureml-msr/models/microsoft-phi-2/version/3?tid=72f988bf-86f1-41af-91ab-2d7cd011db47#overview" target="_blank" rel="noreferrer noopener"><strong>Phi-2</strong><span class="sr-only"> (opens in new tab)</span></a><strong> </strong>available in the Azure AI Studio model catalog to foster research and development on language models.</p>



	<div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-an="promo" data-bi-id="956160">
		

		<p class="msr-promo__label text-gray-800 text-center text-uppercase">
		<span class="px-4 bg-white display-inline-block font-weight-semibold small">Microsoft Research Podcast</span>
	</p>
	
	<div class="row pt-3 pb-4 align-items-center">
						<div class="msr-promo__media col-12 col-md-5">
				<a class="bg-gray-300" href="https://www.phi-2.top/" aria-label="Collaborators: Renewable energy storage with Bichlien Nguyen and David Kwabi" data-bi-cn="Collaborators: Renewable energy storage with Bichlien Nguyen and David Kwabi" target="_blank">
					<img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/06/collaboratorsEP2_hero_1400x788.jpg">
				</a>
			</div>
			
			<div class="msr-promo__content p-3 px-5 col-12 col-md">

									<h2 class="h4">Collaborators: Renewable energy storage with Bichlien Nguyen and David Kwabi</h2>
				
								<p class="large">Dr. Bichlien Nguyen and Dr. David Kwabi explore their work in flow batteries and how machine learning can help more effectively search the vast organic chemistry space to identify compounds with properties just right for storing waterpower and other renewables.</p>
				
								<div class="wp-block-buttons justify-content-center justify-content-md-start">
					<div class="wp-block-button">
						<a href="https://www.microsoft.com/en-us/research/podcast/collaborators-renewable-energy-storage-with-bichlien-nguyen-and-david-kwabi/" class="btn btn-brand glyph-append glyph-append-chevron-right" aria-label="Listen now" data-bi-cn="Collaborators: Renewable energy storage with Bichlien Nguyen and David Kwabi" target="_blank">
							Listen now						</a>
					</div>
				</div>
							</div><!--/.msr-promo__content-->
	</div><!--/.msr-promo__inner-wrap-->
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span>	</div><!--/.msr-promo-->
	


<h2 class="wp-block-heading" id="key-insights-behind-phi-2">Key Insights Behind Phi-2</h2>



<p>The massive increase in the size of language models to hundreds of billions of parameters has unlocked a host of emerging capabilities that have redefined the landscape of natural language processing. A question remains whether such emergent abilities can be achieved at a smaller scale using strategic choices for training, e.g., data selection.</p>



<p>Our line of work with the Phi models aims to answer this question by training SLMs that achieve performance on par with models of much higher scale (yet still far from the frontier models). Our key insights for breaking the conventional language model scaling laws with Phi-2 are twofold:</p>



<p>Firstly, training data quality plays a critical role in model performance. This has been known for decades, but we take this insight to its extreme by focusing on “textbook-quality” data, following upon our prior work “<a href="https://www.microsoft.com/en-us/research/publication/textbooks-are-all-you-need/">Textbooks Are All You Need</a>.” Our training data mixture contains synthetic datasets specifically created to teach the model common sense reasoning and general knowledge, including science, daily activities, and theory of mind, among others. We further augment our training corpus with carefully selected web data that is filtered based on educational value and content quality. Secondly, we use innovative techniques to scale up, starting from our 1.3 billion parameter model, Phi-1.5, and embedding its knowledge within the 2.7 billion parameter Phi-2. This scaled knowledge transfer not only accelerates training convergence but shows clear boost in Phi-2 benchmark scores.</p>



<figure class="wp-block-image aligncenter size-full"><img decoding="async" width="25377" height="5876" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp.png" alt="A bar plot comparing the performance of Phi-2 (with 2.7B parameters) and Phi-1.5 (with 1.3B parameters) on common sense reasoning, language understanding, math, coding, and the Bigbench-hard benchmark. Phi-2 outperforms Phi1.5 in all categories. The commonsense reasoning tasks are PIQA, WinoGrande, ARC easy and challenge, and SIQA. The language understanding tasks are HellaSwag, OpenBookQA, MMLU, SQuADv2, and BoolQ. The math task is GSM8k, and coding includes the HumanEval and MBPP benchmarks. " class="wp-image-991359" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp.png 25377w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp-300x69.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp-1024x237.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp-768x178.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp-1536x356.png 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp-2048x474.png 2048w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp-240x56.png 240w" sizes="(max-width: 25377px) 100vw, 25377px"><figcaption class="wp-element-caption"><strong>Figure 2. </strong>Comparison between Phi-2 (2.7B) and Phi-1.5 (1.3B) models. All tasks are evaluated in 0-shot except for BBH and MMLU which use 3-shot CoT and 5-shot, respectively.</figcaption></figure>



<h2 class="wp-block-heading" id="training-details">Training Details</h2>



<p>Phi-2 is a Transformer-based model with a next-word prediction objective, trained on 1.4T tokens from multiple passes on a mixture of Synthetic and Web datasets for NLP and coding. The training for Phi-2 took 14 days on 96 A100 GPUs. Phi-2 is a base model that has not undergone alignment through reinforcement learning from human feedback (RLHF), nor has it been instruct fine-tuned. Despite this, we observed better behavior with respect to toxicity and bias compared to existing open-source models that went through alignment (see Figure 3). This is in line with what we saw in Phi-1.5 due to our tailored data curation technique, see our <a href="https://www.microsoft.com/en-us/research/publication/textbooks-are-all-you-need-ii-phi-1-5-technical-report/">previous tech report<span class="sr-only"> (opens in new tab)</span></a> for more details on this. For more information about the Phi-2 model, please visit <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://ml.azure.com/registries/azureml-msr/models/microsoft-phi-2/version/3?tid=72f988bf-86f1-41af-91ab-2d7cd011db47#overview" target="_blank" rel="noreferrer noopener">Azure AI | Machine Learning Studio<span class="sr-only"> (opens in new tab)</span></a>.</p>



<figure class="wp-block-image aligncenter size-full"><img decoding="async" width="16803" height="8165" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure3_safety_scores.png" alt="A barplot comparing the safety score of Phi-1.5, Phi-2, and Llama-7B models on 13 categories of the ToxiGen benchmark. Phi-1.5 achieves the highest score on all categories, Phi-2 achieves the second-highest scores and Llama-7B achieves the lowest scores across all categories. " class="wp-image-991365" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure3_safety_scores.png 16803w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure3_safety_scores-300x146.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure3_safety_scores-1024x498.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure3_safety_scores-768x373.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure3_safety_scores-1536x746.png 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure3_safety_scores-2048x995.png 2048w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure3_safety_scores-240x117.png 240w" sizes="(max-width: 16803px) 100vw, 16803px"><figcaption class="wp-element-caption"><strong>Figure 3. </strong>Safety scores computed on 13 demographics from ToxiGen. A subset of 6541 sentences are selected and scored between 0 to 1 based on scaled perplexity and sentence toxicity. A higher score indicates the model is less likely to produce toxic sentences compared to benign ones.</figcaption></figure>



<h2 class="wp-block-heading" id="phi-2-evaluation">Phi-2 Evaluation</h2>



<p>Below, we summarize Phi-2 performance on academic benchmarks compared to popular language models. Our benchmarks span several categories, namely, Big Bench Hard (BBH) (3 shot with CoT), commonsense reasoning (PIQA, WinoGrande, ARC easy and challenge, SIQA), language understanding (HellaSwag, OpenBookQA, MMLU (5-shot), SQuADv2 (2-shot), BoolQ), math (GSM8k (8 shot)), and coding (HumanEval, MBPP (3-shot)).</p>



<p>With only 2.7 billion parameters, Phi-2 surpasses the performance of Mistral and Llama-2 models at 7B and 13B parameters on various aggregated benchmarks. Notably, it achieves better performance compared to 25x larger Llama-2-70B model on muti-step reasoning tasks, i.e., coding and math. Furthermore, Phi-2 matches or outperforms the recently-announced Google Gemini Nano 2, despite being smaller in size.</p>



<p>Of course, we acknowledge the current challenges with model evaluation, and that many public benchmarks might leak into the training data. For our first model, Phi-1, we did an extensive decontamination study to discard this possibility, which can be found in our first report “<a href="https://www.microsoft.com/en-us/research/publication/textbooks-are-all-you-need/">Textbooks Are All You Need</a>.” Ultimately, we believe that the best way to judge a language model is to test it on concrete use cases. Following that spirit, we also evaluated Phi-2 using several Microsoft internal proprietary datasets and tasks, comparing it again to Mistral and Llama-2. We observed similar trends, i.e. on average, Phi-2 outperforms Mistral-7B, and the latter outperforms the Llama-2 models (7B, 13B, and 70B).</p>



<figure class="wp-block-table"><table><thead><tr><th>Model</th><th>Size</th><th>BBH</th><th>Commonsense<br>Reasoning</th><th>Language<br>Understanding</th><th>Math</th><th>Coding</th></tr></thead><tbody><tr><td rowspan="3">Llama-2</td><td>7B</td><td>40.0</td><td>62.2</td><td>56.7</td><td>16.5</td><td>21.0</td></tr><tr><td>13B</td><td>47.8</td><td>65.0</td><td>61.9</td><td>34.2</td><td>25.4</td></tr><tr><td>70B</td><td>66.5</td><td>69.2</td><td>67.6</td><td>64.1</td><td>38.3</td></tr><tr><td>Mistral</td><td>7B</td><td>57.2</td><td>66.4</td><td>63.7</td><td>46.4</td><td>39.4</td></tr><tr><td>Phi-2</td><td>2.7B</td><td>59.2</td><td>68.8</td><td>62.0</td><td>61.1</td><td>53.7</td></tr></tbody></table><figcaption class="wp-element-caption"><center><strong>Table 1.</strong> Averaged performance on grouped benchmarks compared to popular open-source SLMs.</center></figcaption></figure>



<figure class="wp-block-table"><table><thead><tr><th>Model</th><th>Size</th><th>BBH</th><th>BoolQ</th><th>MBPP</th><th>MMLU</th></tr></thead><tbody><tr><td>Gemini Nano 2</td><td>3.2B</td><td>42.4</td><td>79.3</td><td>27.2</td><td>55.8</td></tr><tr><td>Phi-2</td><td>2.7B</td><td>59.3</td><td>83.3</td><td>59.1</td><td>56.7</td></tr></tbody></table><figcaption class="wp-element-caption"><center><strong>Table 2.</strong> Comparison between Phi-2 and Gemini Nano 2 Model on Gemini’s reported benchmarks.</center></figcaption></figure>



<p>In addition to these benchmarks, we also performed extensive testing on commonly used prompts from the research community. We observed a behavior in accordance with the expectation we had given the benchmark results. For example, we tested a prompt used to probe a model’s ability to solve physics problems, most recently used to evaluate the capabilities of the Gemini Ultra model, and achieved the following result:</p>



<figure class="wp-block-image aligncenter size-full"><img decoding="async" width="1347" height="758" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4.png" alt="An example prompt is given to Phi-2 which says “A skier slides down a frictionless slope of height 40m and length 80m. What's the skier’s speed at the bottom?”. Phi-2 then answers the prompt by explaining the conversion of potential energy to kinetic energy and providing the formulas to compute each one. It then proceeds to compute the correct speed using the energy formulas. " class="wp-image-991326" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4.png 1347w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-343x193.png 343w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-1280x720.png 1280w" sizes="(max-width: 1347px) 100vw, 1347px"><figcaption class="wp-element-caption"><strong>Figure 4. </strong>Phi-2’s output on a simple physics problem, which includes an approximately correct square root calculation.</figcaption></figure>



<figure class="wp-block-image aligncenter size-full"><img decoding="async" width="1600" height="710" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig5.png" alt="The model is then provided with a student’s wrong answer to the skier physics problem and asked if it can correct the student’s mistake. Phi-2 replies with the student’s mistake, i.e., using the wrong formula for potential energy, and provides the correct formula. " class="wp-image-991332" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig5.png 1600w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig5-300x133.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig5-1024x454.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig5-768x341.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig5-1536x682.png 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig5-240x107.png 240w" sizes="(max-width: 1600px) 100vw, 1600px"><figcaption class="wp-element-caption"><strong>Figure 5. </strong>Similarly to Gemini’s test we also further queried Phi-2 with a student’s wrong answer to see if Phi-2 could identify where the mistake is (it did, despite Phi-2 being not fine-tuned for chat or instruction-following). We note however that it is not fully an apple-to-apple comparison with the Gemini Ultra’s output described in the Gemini report, in particular in the latter case the student’s answer was given as an image with handwritten text rather than raw text in our case.</figcaption></figure>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span>					
</div>
	      
<section>
    <!-- Container -->
    <div class="mx-auto w-full max-w-7xl px-5 py-16 md:px-10 md:py-24 lg:py-32">
      <!-- Component -->
      <div class="flex flex-col items-start gap-8 sm:gap-20 lg:flex-row lg:items-center">
        <div class="lg:w-1/2">
          <h2 class="mb-4 max-w-3xl text-3xl font-bold md:text-5xl">Phi-1 is a compact and powerful model.</h2>
          <p class="mb-6 max-w-lg text-sm text-[#636262] sm:text-base md:mb-10 lg:mb-12">The language model phi-1 is a Transformer with 1.3 billion parameters, specialized for basic Python coding. Its training involved a variety of data sources, including subsets of Python codes from The Stack v1.2, Q&A content from StackOverflow, competition code from code_contests, and synthetic Python textbooks and exercises generated by gpt-3.5-turbo-0301. </p>
          <a href="#" class="inline-block bg-black px-6 py-3 font-semibold text-white">Phi-1</a>
        </div>
        <div class="lg:w-1/2">
          <img src="https://phi-2.top/img/phi-1.png" alt="phi-1" />
        </div>
      </div>
    </div>
  </section>
  
<section>
    <!-- Container -->
    <div class="mx-auto w-full max-w-7xl px-5 py-16 md:px-10 md:py-24 lg:py-32">
      <!-- Component -->
      <div class="flex flex-col items-start gap-8 sm:gap-20 lg:flex-row-reverse lg:items-center">
        <div class="lg:w-1/2">
          <h2 class="mb-4 max-w-3xl text-3xl font-bold md:text-5xl">Phi-1.5 is a language model with 130 million parameters</h2>
          <p class="mb-6 max-w-lg text-sm text-[#636262] sm:text-base md:mb-10 lg:mb-12">phi-1.5, which is mainly trained based on artificially synthesized data sets, achieves common sense reasoning capabilities similar to those of models 10 times the size. The model is trained using synthetic “textbook-style” data and contains a large amount of common sense reasoning and world knowledge. phi-1.5 uses a 24-layer Transformer architecture with 32 heads and 64 dimensions.</p>
          <a href="#" class="inline-block bg-black px-6 py-3 font-semibold text-white">phi-1.5</a>
        </div>
        <div class="lg:w-1/2">
          <img src="https://phi-2.top/img/phi-1_5.png" alt="phi-1.5" />
        </div>
      </div>
    </div>
  </section>

  <script
  type="module"
  src="https://gradio.s3-us-west-2.amazonaws.com/3.43.2/gradio.js"
></script>

<gradio-app src="https://bigcode-bigcode-models-leaderboard.hf.space"></gradio-app><div>

</div>

  <section>
    <!-- Container -->
    <div class="mx-auto w-full max-w-7xl px-5 py-16 md:px-10 md:py-24 lg:py-32">
      <!-- Component -->
      <div class="flex flex-col items-center">
        <h2 class="text-center text-3xl font-bold md:text-5xl">The latest and greatest news</h2>
        <p class="mb-8 mt-4 text-center text-sm text-[#636262] sm:text-base md:mb-12 lg:mb-16">Lorem ipsum dolor sit amet elit ut aliquam</p>
        <!-- Content -->
        <div class="mb-8 grid gap-5 sm:grid-cols-2 sm:justify-items-stretch md:mb-12 md:grid-cols-3 lg:mb-16 lg:gap-6">
          <!-- Item -->
          <a href="#" class="flex flex-col gap-4 rounded-md px-4 py-8 md:p-0">
            <img src="https://assets.website-files.com/6458c625291a94a195e6cf3a/6458c625291a94016de6cf90_Rectangle%2035.svg" alt="" class="h-60 object-cover" />
            <div class="flex flex-col items-start py-4">
              <div class="mb-4 rounded-md bg-[#f2f2f7] px-2 py-1.5">
                <p class="text-sm font-semibold text-[#6574f8]">CATEGORY NAME</p>
              </div>
              <p class="mb-4 text-xl font-bold md:text-2xl">The latest news with Flowspark</p>
              <div class="flex flex-col items-start text-sm text-[#636262] lg:flex-row lg:items-center">
                <p>Laila Bahar</p>
                <p class="mx-2 hidden lg:block">-</p>
                <p>6 mins read</p>
              </div>
            </div>
          </a>
          <!-- Item -->
          <a href="#" class="flex flex-col gap-4 rounded-md px-4 py-8 md:p-0">
            <img src="https://assets.website-files.com/6458c625291a94a195e6cf3a/6458c625291a94016de6cf90_Rectangle%2035.svg" alt="" class="h-60 object-cover" />
            <div class="flex flex-col items-start py-4">
              <div class="mb-4 rounded-md bg-[#f2f2f7] px-2 py-1.5">
                <p class="text-sm font-semibold text-[#6574f8]">CATEGORY NAME</p>
              </div>
              <p class="mb-4 text-xl font-bold md:text-2xl">The latest news with Flowspark</p>
              <div class="flex flex-col items-start text-sm text-[#636262] lg:flex-row lg:items-center">
                <p>Laila Bahar</p>
                <p class="mx-2 hidden lg:block">-</p>
                <p>6 mins read</p>
              </div>
            </div>
          </a>
          <!-- Item -->
          <a href="#" class="flex flex-col gap-4 rounded-md px-4 py-8 md:p-0">
            <img src="https://assets.website-files.com/6458c625291a94a195e6cf3a/6458c625291a94016de6cf90_Rectangle%2035.svg" alt="" class="h-60 object-cover" />
            <div class="flex flex-col items-start py-4">
              <div class="mb-4 rounded-md bg-[#f2f2f7] px-2 py-1.5">
                <p class="text-sm font-semibold text-[#6574f8]">CATEGORY NAME</p>
              </div>
              <p class="mb-4 text-xl font-bold md:text-2xl">The latest news with Flowspark</p>
              <div class="flex flex-col items-start text-sm text-[#636262] lg:flex-row lg:items-center">
                <p>Laila Bahar</p>
                <p class="mx-2 hidden lg:block">-</p>
                <p>6 mins read</p>
              </div>
            </div>
          </a>
        </div>
        <!-- Button -->
        <a href="#" class="rounded-md bg-black px-6 py-3 text-center font-semibold text-white">View More</a>
      </div>
    </div>
  </section>
  


  <section>
    <div class="justify-centermx-auto flex w-full max-w-7xl flex-col items-center px-5 py-16 md:px-10 md:py-24 lg:py-32">
      <!-- TEXT DIV -->
      <div class="mx-auto flex max-w-[550px] flex-col items-center justify-center px-6 text-center lg:max-w-[800px] lg:px-10">
        <p class="font-inter mb-2 text-center text-sm font-medium"></p>
        <h2 class="mx-auto text-center font-bold text-black lg: text-3xl lg:text-4xl">Frequently Asked Questions</h2>
        <p class="font-inter mt-4 max-w-[600px] px-5 text-center text-base font-light text-[#71717A] lg:max-w-[500px] lg:">How to used Phi models</p>
      </div>
      <!-- FAQs -->
      <div class="mt-10 flex w-full flex-col">
        <!-- FAQ BLOCK -->
        <div class="relative my-3 w-full rounded-md px-12 py-8">
          <div class="max-w-[700px]">
            <h3 class="font-bold text-black text-xl">What is Microsoft's phi-1 model? What can it do?</h3>
            <p class="font-inter mt-4 text-base font-light text-gray-500">phi-1 is intended for research purposes. The model-generated code should be treated as a starting point rather than a definitive solution for potential use cases. Users should be cautious when employing this model in their applications.</p>
          </div>
          <a href="" class="absolute right-5 top-9">
            <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
              <circle cx="12" cy="12" r="12" fill="white"></circle>
              <path d="M7.04688 11.9999H16.9469" stroke="black" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
          </a>
        </div>
        <div class="mx-12 border border-gray-200"></div>
        <!-- FAQ BLOCK -->
        <div class="relative my-3 w-full rounded-md px-12 py-8">
          <div class="max-w-[700px]">
            <h3 class="font-bold text-black text-xl">What is Microsoft's phi-1.5 model? What can it do?</h3>
            <p class="font-inter mt-4 text-base font-light text-gray-500">Given the nature of the training data, phi-1.5 is best suited for prompts using the QA format, the chat format, and the code format. Note that phi-1.5, being a base model, often produces irrelevant text following the main answer. In the following example, we've truncated the answer for illustrative purposes only.</p>
          </div>
          <a href="" class="absolute right-5 top-9">
            <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
              <circle cx="12" cy="12" r="12" fill="white"></circle>
              <path d="M7.05078 12H16.9508" stroke="black" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path>
              <path d="M12 7.05005V16.95" stroke="black" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
          </a>
        </div>
        <div class="mx-12 border border-gray-200"></div>
        <!-- FAQ BLOCK -->
        <div class="relative my-3 w-full rounded-md px-12 py-8">
          <div class="max-w-[700px]">
            <h3 class="font-bold text-black text-xl">What is Microsoft's phi-2 model? What can it Used?</h3>
            <p class="font-inter mt-4 text-base font-light text-gray-500">The massive increase in the size of language models to hundreds of billions of parameters has unlocked a host of emerging capabilities that have redefined the landscape of natural language processing. A question remains whether such emergent abilities can be achieved at a smaller scale using strategic choices for training, e.g., data selection.

                Our line of work with the Phi models aims to answer this question by training SLMs that achieve performance on par with models of much higher scale (yet still far from the frontier models). Our key insights for breaking the conventional language model scaling laws with Phi-2 are twofold:.</p>
          </div>
          <a href="" class="absolute right-5 top-9">
            <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
              <circle cx="12" cy="12" r="12" fill="white"></circle>
              <path d="M7.05078 12H16.9508" stroke="black" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path>
              <path d="M12 7.05005V16.95" stroke="black" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path>
            </svg>
          </a>
        </div>
        <div class="mx-12 border border-gray-200"></div>
        
        
    </div>
  </section>

  <section>
    <!-- Container -->
    <div class="mx-auto w-full max-w-7xl px-5 py-16 md:px-10 md:py-24 lg:py-32">
      <!-- Component -->
      <div class="bg-[#f2f2f7] p-8 text-center sm:p-10 md:p-16">
        <!-- Title -->
        <h2 class="mb-4 text-3xl font-bold md:text-5xl">Join the Phi-2.Top Community</h2>
        <p class="mx-auto mb-6 max-w-2xl text-sm text-[#636262] sm:text-base md:mb-10 lg:mb-12">How to used Phi models</p>
        <div class="mx-auto mb-4 flex max-w-lg justify-center">
          <form name="email-form" method="get" class="flex w-full flex-col gap-3 sm:flex-row">
            <input type="email" class="h-9 w-full rounded-md border border-solid border-black px-3 py-6 text-sm text-[#333333]" placeholder="Enter your email" />
            <input type="submit" value="Notify me" class="cursor-pointer rounded-md bg-black px-6 py-2 font-semibold text-white" />
          </form>
        </div>
      </div>
    </div>
  </section>
  
  <footer class="block">
      <!-- Container -->
      <div class="mx-auto w-full max-w-7xl px-5 py-16 md:px-10 md:py-24 lg:py-32">
        <!-- Component -->
        <div class="flex flex-col items-center">
          <a href="#" class="mb-8 inline-block max-w-full text-black">
            <img src="https://upload.wikimedia.org/wikipedia/commons/2/28/Phi.svg" alt="" class="inline-block max-h-10" />
          </a>
          <div class="max-[991px]: text-center font-semibold max-[991px]:py-1">
            <a href="#" class="inline-block px-6 py-2 font-normal text-black transition hover:text-[#d6a701]">About</a>
            <a href="#" class="inline-block px-6 py-2 font-normal text-black transition hover:text-[#d6a701]">Phi-2</a>
            <a href="#" class="inline-block px-6 py-2 font-normal text-black transition hover:text-[#d6a701]">Phi-1/1.5</a>
            <a href="#" class="inline-block px-6 py-2 font-normal text-black transition hover:text-[#d6a701]">Terms of Service</a>
            <a href="#" class="inline-block px-6 py-2 font-normal text-black transition hover:text-[#d6a701]">Help</a>
          </div>
          <div class="mb-8 mt-8 w-48 [border-bottom:1px_solid_rgb(0,_0,_0)]"></div>
          <div class="mb-12 grid w-full max-w-[208px] grid-flow-col grid-cols-4 gap-3">
           
          </div>
          <p class="max-[479px]:text-sm">© Copyright 2023. All rights reserved.</p>
        </div>
      </div>
    </footer>
  </body>
  </html>
